{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3108c0-6bd7-4608-8495-62e19a6117fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file without headers\n",
    "address = '~/Documents/ce889_dataCollection.csv'\n",
    "add = pd.read_csv(address, header=None)\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(add)\n",
    "\n",
    "# Step 2: Normalize each column\n",
    "normalized_add = (add - add.min()) / (add.max() - add.min())\n",
    "\n",
    "# Print the normalized DataFrame\n",
    "print(\"\\nNormalized DataFrame:\")\n",
    "print(normalized_add)\n",
    "\n",
    "normalized_address = '~/Documents/normalized_dataCollection.csv'\n",
    "normalized_add.to_csv(normalized_address, index=False, header=False)\n",
    "\n",
    "print(f\"\\nNormalized data saved to {normalized_address}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5920bc6-e620-447f-be6e-155fa224b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Step 1: Read your normalized CSV file\n",
    "# Assuming the first row contains column headers\n",
    "data = pd.read_csv('normalized_dataCollection.csv')\n",
    "\n",
    "# Step 2: Extract input and output data\n",
    "# Columns x1 and x2 are assumed to be the first two columns\n",
    "# Columns y1 and y2 are assumed to be the next two columns\n",
    "input_data = data.iloc[:, 0:2].values  # Input data\n",
    "output_data = data.iloc[:, 2:4].values  # Output data\n",
    "\n",
    "# Step 3: Split the data into training and testing datasets (70% training and 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Transpose the input and output data\n",
    "# Transposing is not always necessary in Python since NumPy and TensorFlow handle input shapes differently than MATLAB\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "# Step 5: Create and train your neural network model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(3, activation='sigmoid', input_shape=(2,)),  # 3 neurons in hidden layer\n",
    "    layers.Dense(2)  # Output layer with 2 outputs\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.5, momentum=0.9),\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train.T, y_train.T, epochs=100, verbose=1)  # Transpose back for fitting\n",
    "\n",
    "# Step 6: Get predicted outputs\n",
    "y_pred = model.predict(X_train.T)  # You can also use X_test.T for predictions on the test set\n",
    "\n",
    "# If needed, convert the predicted outputs back to a DataFrame for easier analysis\n",
    "predicted_outputs = pd.DataFrame(y_pred, columns=['y1_pred', 'y2_pred'])\n",
    "\n",
    "print(predicted_outputs.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
